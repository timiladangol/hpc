{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Module 3: Using HPC for Computational Tasks**\n",
    "- **Basics of Python:** Basics of Python and why do you use Python. Anaconda and Spyder\n",
    "- **Running Jobs on HPC Systems:** Learn how to submit, monitor, and manage jobs on an HPC cluster.\n",
    "- **Batch Processing and Job Scheduling:** Understand how batch processing works and how to use job schedulers like SLURM or PBS.\n",
    "- **Optimizing Job Performance:** Tips on optimizing computational tasks to make the most of HPC resources.\n",
    "- **Handling Large Data Sets:** Learn techniques for managing and processing large data sets on HPC systems.\n",
    "- **Common HPC Workflows:** Explore typical workflows and examples of tasks that can be completed using HPC.\n",
    "\n",
    "**Learning Outcome:** Students will gain the skills to effectively run and manage computational tasks on HPC systems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python, Anaconda, and Spyder\n",
    "\n",
    "## 1. Introduction to Python\n",
    "\n",
    "Python is a versatile, high-level programming language known for its simplicity and readability. It’s widely used in various fields like web development, data science, artificial intelligence, and more.\n",
    "\n",
    "### Why Learn Python?\n",
    "- **Easy to Learn and Use**: Python’s syntax is clear and simple, making it an ideal choice for beginners.\n",
    "- **Versatile**: Python can be used for a wide range of applications, from web development to data analysis.\n",
    "- **Strong Community Support**: Python has a large and active community, providing extensive resources and libraries.\n",
    "\n",
    "### Basic Python Syntax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a comment\n",
    "print(\"Hello, World!\")  # Output: Hello, World!\n",
    "\n",
    "# Variables\n",
    "x = 5\n",
    "y = \"Python\"\n",
    "print(x, y)  # Output: 5 Python\n",
    "\n",
    "# Simple Arithmetic\n",
    "a = 10\n",
    "b = 3\n",
    "print(a + b)  # Addition: Output: 13\n",
    "print(a - b)  # Subtraction: Output: 7\n",
    "print(a * b)  # Multiplication: Output: 30\n",
    "print(a / b)  # Division: Output: 3.3333..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Data Structures Examples\n",
    "\n",
    "#### 1. Dictionary\n",
    "\n",
    "A dictionary in Python is a collection of key-value pairs. Each key is unique, and it is used to store and retrieve values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = {\n",
    "    \"name\": \"John Doe\",\n",
    "    \"age\": 21,\n",
    "    \"major\": \"Computer Science\"\n",
    "}\n",
    "\n",
    "# Accessing values\n",
    "print(student[\"name\"])  # Output: John Doe\n",
    "\n",
    "# Adding a new key-value pair\n",
    "student[\"grade\"] = \"A\"\n",
    "\n",
    "# Updating a value\n",
    "student[\"age\"] = 22\n",
    "\n",
    "# Deleting a key-value pair\n",
    "del student[\"major\"]\n",
    "\n",
    "print(student)\n",
    "# Output: {'name': 'John Doe', 'age': 22, 'grade': 'A'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A set is an unordered collection of unique elements. Sets are useful for removing duplicates \n",
    "and performing mathematical set operations like union, intersection, etc.'''\n",
    "# Creating a set\n",
    "fruits = {\"apple\", \"banana\", \"cherry\"}\n",
    "\n",
    "# Adding an element\n",
    "fruits.add(\"orange\")\n",
    "\n",
    "# Removing an element\n",
    "fruits.remove(\"banana\")\n",
    "\n",
    "# Checking membership\n",
    "print(\"apple\" in fruits)  # Output: True\n",
    "\n",
    "# Set operations\n",
    "set1 = {1, 2, 3}\n",
    "set2 = {3, 4, 5}\n",
    "\n",
    "# Union\n",
    "print(set1 | set2)  # Output: {1, 2, 3, 4, 5}\n",
    "\n",
    "# Intersection\n",
    "print(set1 & set2)  # Output: {3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A tuple is an immutable sequence of elements. \n",
    "Once created, the elements of a tuple cannot be changed.'''\n",
    "# Creating a tuple\n",
    "coordinates = (10.0, 20.0, 30.0)\n",
    "\n",
    "# Accessing elements\n",
    "print(coordinates[0])  # Output: 10.0\n",
    "\n",
    "# Unpacking a tuple\n",
    "x, y, z = coordinates\n",
    "print(x, y, z)  # Output: 10.0 20.0 30.0\n",
    "\n",
    "# Tuples are immutable, so the following line would raise an error:\n",
    "# coordinates[0] = 15.0  # Uncommenting this will raise a TypeError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A list is an ordered collection of elements. Lists are mutable, \n",
    "meaning their elements can be changed after creation.'''\n",
    "# Creating a list\n",
    "colors = [\"red\", \"green\", \"blue\"]\n",
    "\n",
    "# Adding an element\n",
    "colors.append(\"yellow\")\n",
    "\n",
    "# Removing an element\n",
    "colors.remove(\"green\")\n",
    "\n",
    "# Accessing elements\n",
    "print(colors[1])  # Output: blue\n",
    "\n",
    "# Slicing a list\n",
    "print(colors[0:2])  # Output: ['red', 'blue']\n",
    "\n",
    "# Sorting a list\n",
    "colors.sort()\n",
    "print(colors)  # Output: ['blue', 'red', 'yellow']\n",
    "\n",
    "# List comprehension is a concise way to create lists.\n",
    "# List of squares of numbers from 0 to 9\n",
    "squares = [x**2 for x in range(10)]\n",
    "print(squares)  # Output: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Python allows you to nest data structures, \n",
    "such as lists within dictionaries, or dictionaries within lists.'''\n",
    "# Creating a dictionary with lists as values\n",
    "grades = {\n",
    "    \"math\": [90, 85, 88],\n",
    "    \"science\": [92, 81, 79],\n",
    "    \"english\": [87, 94, 91]\n",
    "}\n",
    "\n",
    "# Accessing a list from the dictionary\n",
    "print(grades[\"math\"])  # Output: [90, 85, 88]\n",
    "\n",
    "# Adding a new score to the science list\n",
    "grades[\"science\"].append(85)\n",
    "print(grades[\"science\"])  # Output: [92, 81, 79, 85]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of dictionaries\n",
    "students = [\n",
    "    {\"name\": \"John\", \"age\": 21},\n",
    "    {\"name\": \"Alice\", \"age\": 23},\n",
    "    {\"name\": \"Bob\", \"age\": 22}\n",
    "]\n",
    "\n",
    "# Accessing the first student's name\n",
    "print(students[0][\"name\"])  # Output: John\n",
    "\n",
    "# Adding a new student\n",
    "students.append({\"name\": \"Eve\", \"age\": 20})\n",
    "print(students)\n",
    "# Output: [{'name': 'John', 'age': 21}, {'name': 'Alice', 'age': 23}, {'name': 'Bob', 'age': 22}, {'name': 'Eve', 'age': 20}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to Anaconda (Optional)\n",
    "\n",
    "Anaconda is a free and open-source distribution of Python and R programming languages. It’s used for scientific computing and data science, simplifying package management and deployment.\n",
    "\n",
    "#### Key Features of Anaconda:\n",
    "- **Comes with Python**: Anaconda installs Python automatically.\n",
    "- **Package Management**: Anaconda includes conda, a package manager that makes it easy to install, update, and manage libraries and dependencies.\n",
    "- **Integrated Development Environments (IDEs)**: Anaconda comes with IDEs like Jupyter Notebook and Spyder.\n",
    "\n",
    "#### Table of Commands for Managing Anaconda Environments and Packages\n",
    "\n",
    "| Command | Description |\n",
    "| --- | --- |\n",
    "| `conda install <package>` | Installs a single package or a list of packages. (e.g., `conda install numpy`, `conda install numpy pandas matplotlib`) |\n",
    "| `conda update <package>` | Updates a specific package to the latest version. (e.g., `conda update numpy`) |\n",
    "| `conda update --all` | Updates all packages in the current environment. |\n",
    "| `conda remove <package>` | Removes a single package or a list of packages from the current environment. (e.g., `conda remove numpy`) |\n",
    "| `conda env export > environment.yaml` | Exports the current environment to a YAML file named `environment.yaml`. |\n",
    "| `conda env create -f environment.yaml` | Creates an environment from a YAML file. (e.g., creates an environment from `environment.yaml`) |\n",
    "| `anaconda-navigator` | Launches Anaconda Navigator from the terminal. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Spyder\n",
    "\n",
    "Spyder (Scientific Python Development Environment) is an open-source Integrated Development Environment (IDE) designed for Python. It is particularly useful for scientific computing and data science, offering tools for editing, debugging, and profiling Python code.\n",
    "\n",
    "#### Key Features of Spyder\n",
    "- **Interactive Console**: Allows you to run Python code interactively, see the output immediately, and experiment with your code.\n",
    "- **Variable Explorer**: Lets you view and manage the variables in your code, including data types and values, in a convenient, table-like format.\n",
    "- **Integrated Development Environment (IDE)**: Combines a powerful code editor, debugging tools, and more in one interface.\n",
    "- **Support for Scientific Libraries**: Spyder comes with support for scientific libraries like NumPy, SciPy, Matplotlib, and others, making it ideal for data analysis.\n",
    "\n",
    "#### Getting Started with Spyder\n",
    "\n",
    "##### Step 1: Launching Spyder\n",
    "\n",
    "1. Open Anaconda Navigator.\n",
    "2. Click on \"Launch\" under the Spyder icon.\n",
    "\n",
    "##### Step 2: Writing Your First Script\n",
    "\n",
    "1. In the Spyder interface, you’ll see the code editor on the left, the console at the bottom right, and the variable explorer at the top right.\n",
    "2. Start by typing the following code in the code editor:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python\n",
    "# Simple Python Script in Spyder\n",
    "import numpy as np\n",
    "\n",
    "# Creating an array\n",
    "array = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Printing the array\n",
    "print(\"Array:\", array)\n",
    "\n",
    "# Performing a basic operation\n",
    "squared_array = array ** 2\n",
    "print(\"Squared Array:\", squared_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You can save the script\n",
    "4. Run the script \n",
    "##### Step 3: Using the Variable Explorer\n",
    "After running the script, take a look at the Variable Explorer on the top right:\n",
    "\n",
    "You’ll see array and squared_array listed with their corresponding data types and values.\n",
    "Double-click on a variable to view its contents in detail.\n",
    "##### Step 4: Interactive Coding in the Console\n",
    "Spyder’s IPython console allows for interactive coding. You can run commands and see the output instantly.\n",
    "\n",
    "1. Click on the console at the bottom.\n",
    "2. Try running the following commands interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Console Example\n",
    "import math\n",
    "\n",
    "# Calculate the square root of 16\n",
    "sqrt_value = math.sqrt(16)\n",
    "print(\"Square Root of 16:\", sqrt_value)\n",
    "\n",
    "# Calculate the sine of 90 degrees (converted to radians)\n",
    "sine_value = math.sin(math.radians(90))\n",
    "print(\"Sine of 90 degrees:\", sine_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll see the results immediately in the console. This is a great way to test small pieces of code quickly.\n",
    "\n",
    "Example 1: Plotting Data\n",
    "You can use Spyder to create and visualize data plots interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creating data\n",
    "x = [0, 1, 2, 3, 4, 5]\n",
    "y = [0, 1, 4, 9, 16, 25]\n",
    "\n",
    "# Plotting the data\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Simple Plot\")\n",
    "plt.xlabel(\"x-axis\")\n",
    "plt.ylabel(\"y-axis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spyder has built-in debugging tools that make it easy to step through your code, inspect variables, and understand what’s happening. //(ADD A VIDEO LATER ON THIS TO ILLUSTRATE)\n",
    "1. Place a breakpoint by clicking to the left of the line numbers in the editor.\n",
    "2. Run the script in debug mode by clicking the debug button (green play button with a bug icon).\n",
    "3. Step through the code line by line using the debug toolbar.\n",
    "This helps in understanding how your code executes and in catching any errors or bugs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging Example\n",
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n - 1)\n",
    "\n",
    "# Test the function\n",
    "result = factorial(5)\n",
    "print(\"Factorial of 5:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Job Performance on HPC Systems\n",
    "\n",
    "## Introduction to High-Performance Computing (HPC) //ADD PICTURE OF HPC SETUP OR WORKFLOW\n",
    "\n",
    "High-Performance Computing (HPC) refers to the use of supercomputers and parallel processing techniques to solve complex computational problems. HPC systems allow for massive computational power, enabling researchers and engineers to perform simulations, data analysis, and other tasks that would be infeasible on standard computers.\n",
    "\n",
    "However, to make the most of HPC resources, it's crucial to optimize your computational tasks. Proper optimization can lead to significant improvements in performance, resource utilization, and overall efficiency.\n",
    "\n",
    "## 1. Understanding HPC Architecture\n",
    "\n",
    "### Key Components of HPC Systems\n",
    "- **Nodes**: Individual computers within an HPC system. Each node typically contains CPUs, memory, and storage.\n",
    "- **CPUs and Cores**: The central processing units (CPUs) in each node, often consisting of multiple cores that can run tasks in parallel.\n",
    "- **Interconnect**: The network that connects the nodes, allowing them to communicate and share data.\n",
    "- **Storage**: High-speed storage systems that provide the necessary read/write speeds for large datasets.\n",
    "\n",
    "Understanding the architecture of your HPC system is crucial for optimizing performance. Different systems may have varying numbers of cores per node, memory configurations, and interconnect speeds, all of which influence how you should optimize your jobs.\n",
    "\n",
    "## 2. Efficient Resource Allocation\n",
    "\n",
    "### Right-Sizing Jobs\n",
    "- **Request Only What You Need**: When submitting jobs, request only the number of cores, memory, and wall time you need. Over-requesting resources can lead to inefficient use of the HPC system and longer queue times.\n",
    "- **Use Node Resources Efficiently**: Ensure that you are fully utilizing the CPUs and memory on each node. For multi-threaded applications, consider using thread affinity settings to bind threads to specific cores. (produce a video later on)\n",
    "\n",
    "### Example: Job Script for a Multi-Core Task\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=my_job          # Job name\n",
    "#SBATCH --nodes=2                  # Number of nodes\n",
    "#SBATCH --ntasks-per-node=16       # Number of tasks per node\n",
    "#SBATCH --time=04:00:00            # Wall time limit (HH:MM:SS)\n",
    "#SBATCH --mem=64GB                 # Memory per node\n",
    "#SBATCH --output=output_%j.log     # Standard output log\n",
    "\n",
    "# Load necessary modules\n",
    "module load python/3.8\n",
    "\n",
    "# Run the program\n",
    "srun --mpi=pmi2 python my_script.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerations for Resource Allocation\n",
    "- **Memory Usage:** Monitor the memory usage of your jobs and adjust your requests accordingly. Use tools like top or htop to observe real-time memory usage.\n",
    "- **Job Arrays:** If you have many similar tasks, use job arrays to submit them in a single batch job. This reduces the overhead of job submission and improves scheduling efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelization Strategies\n",
    "**1.  Data Parallelism**\n",
    "Split Data Across Nodes: Divide your dataset into smaller chunks that can be processed in parallel across multiple nodes. This is particularly effective for large-scale simulations or data analysis tasks.\n",
    "\n",
    "**2.  Task Parallelism**\n",
    "Divide and Conquer: Break down a large computational task into smaller, independent tasks that can be executed concurrently. This strategy is effective for problems that can be naturally decomposed, such as Monte Carlo simulations.\n",
    "\n",
    "**3. Hybrid Parallelism**\n",
    "Combine MPI and OpenMP: For applications that require both distributed memory (MPI) and shared memory (OpenMP) parallelism, consider a hybrid approach. MPI can be used to communicate between nodes, while OpenMP manages parallelism within each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// an example: Hybrid MPI/OpenMP Code Structure\n",
    "//in C\n",
    "#include <mpi.h>\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char *argv[]) \n",
    "{\n",
    "    MPI_Init(&argc, &argv);  // Initialize MPI\n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        int thread_id = omp_get_thread_num();\n",
    "        printf(\"Hello from thread %d of process %d\\n\", thread_id, rank);\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();  // Finalize MPI\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Data I/O\n",
    "\n",
    "1. **Minimize I/O Operations**:\n",
    "   - Reduce the frequency of reading/writing to disk. Use in-memory computations where possible to avoid slow disk I/O.\n",
    "\n",
    "2. **Use High-Speed Storage**:\n",
    "   - Store large datasets on high-speed storage (e.g., SSDs or parallel file systems like Lustre) to minimize I/O bottlenecks.\n",
    "\n",
    "3. **Efficient File Handling**:\n",
    "   - When reading or writing large files, use efficient file formats (e.g., HDF5, NetCDF) that support parallel I/O.\n",
    "\n",
    "### Load Balancing and Task Scheduling\n",
    "\n",
    "1. **Load Balancing**:\n",
    "   - Ensure that computational tasks are evenly distributed across all available cores/nodes. Uneven load distribution can cause some nodes to sit idle while others are overworked.\n",
    "\n",
    "2. **Task Scheduling**:\n",
    "   - Schedule tasks in a way that maximizes resource utilization. For example, staggered start times for large jobs can help avoid peak load times on the cluster.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is loaded into memory, processed with a mathematical operation, and then written to disk only once. This minimizes the number of I/O operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''python'''\n",
    "''' Efficient Data Processing Using In-Memory Computation '''\n",
    "\n",
    "''' sometimes, Instead of frequently reading and writing data to disk, \n",
    "you can load data into memory, process it, \n",
    "and write the results back to disk in one go. \n",
    "This reduces the overhead associated with disk I/O.'''\n",
    "import numpy as np\n",
    "\n",
    "# Generate a large dataset (e.g., a 10000x10000 array)\n",
    "data = np.random.rand(10000, 10000)\n",
    "\n",
    "# Perform some in-memory computations\n",
    "processed_data = np.sqrt(data)  # Example operation: compute square root\n",
    "\n",
    "# Write the processed data to disk\n",
    "np.save('processed_data.npy', processed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HDF5 format is used to store a large array. Writing and reading operations are performed in a way that optimizes I/O performance, especially when working with large datasets.\n",
    "//grammar error in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Using The dataset is loaded into memory, processed with a mathematical operation, and then written to disk only once. \n",
    "This minimizes the number of I/O operations.'''\n",
    "'''Writing and Reading Large Files with HDF5\n",
    "HDF5 is a file format that supports the storage of large datasets \n",
    "and is optimized for fast I/O operations. \n",
    "It's particularly useful when dealing with big data.'''\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Create a large dataset\n",
    "data = np.random.rand(10000, 10000)\n",
    "\n",
    "# Write data to an HDF5 file\n",
    "with h5py.File('data.h5', 'w') as hf:\n",
    "    hf.create_dataset('dataset_1', data=data)\n",
    "\n",
    "# Read data back from the HDF5 file\n",
    "with h5py.File('data.h5', 'r') as hf:\n",
    "    read_data = hf['dataset_1'][:]\n",
    "\n",
    "print(read_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Buffered I/O for Large Text Files\n",
    "\n",
    "Buffered I/O allows you to read and write large files in chunks, reducing memory usage and speeding up I/O operations.\n",
    "\n",
    "For the program below, the file is written in chunks rather than all at once, and it’s read back using a 1 MB buffer. This method is efficient for handling large files, as it reduces memory usage and speeds up both reading and writing operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to a large text file using buffered I/O\n",
    "with open('large_file.txt', 'w') as f:\n",
    "    for i in range(1000000):\n",
    "        f.write(f\"Line {i}\\n\")\n",
    "\n",
    "# Reading from the large text file in chunks\n",
    "with open('large_file.txt', 'r') as f:\n",
    "    buffer_size = 1024 * 1024  # 1 MB buffer\n",
    "    while True:\n",
    "        data = f.read(buffer_size)\n",
    "        if not data:\n",
    "            break\n",
    "        # Process the data\n",
    "        print(f\"Read {len(data)} bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel I/O with MPI\n",
    "\n",
    "Example: Using MPI for Parallel File Writing\n",
    "\n",
    "MPI (Message Passing Interface) can be used to write data to a file in parallel, distributing the workload across multiple processors or nodes.\n",
    "\n",
    "This example below demonstrates how to use MPI for parallel file writing, where each process writes its own portion of data to the file. The use of MPI.Barrier() ensures that all processes have finished writing before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "# Each process creates its own portion of the data\n",
    "data = np.arange(1000 * rank, 1000 * (rank + 1))\n",
    "\n",
    "# Parallel write to a binary file\n",
    "with open('parallel_data.bin', 'wb') as f:\n",
    "    f.seek(rank * len(data) * data.itemsize)  # Seek to the correct position\n",
    "    f.write(data.tobytes())\n",
    "\n",
    "# Use MPI barrier to ensure all processes have finished writing\n",
    "comm.Barrier()\n",
    "\n",
    "# Read back the data in parallel (for validation)\n",
    "with open('parallel_data.bin', 'rb') as f:\n",
    "    f.seek(rank * len(data) * data.itemsize)\n",
    "    read_data = np.frombuffer(f.read(len(data) * data.itemsize), dtype=data.dtype)\n",
    "\n",
    "print(f\"Process {rank} read data: {read_data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring and Profiling Jobs\n",
    "\n",
    "### Monitor Job Performance\n",
    "\n",
    "1. **Use Job Monitoring Tools**:\n",
    "   - Monitor your job's memory, and I/O usage using available HPC tools (e.g., `top`, `htop`, `qstat`). This helps identify bottlenecks and inefficient resource usage.\n",
    "   \n",
    "   //SS OF RESPONSE ON TERMINAL FOR top htop qstat\n",
    "\n",
    "2. **Adjust Based on Feedback**:\n",
    "   - If your job consistently underutilizes resources (e.g., low CPU usage), adjust the resource requests for future jobs.\n",
    "\n",
    "### Profiling and Debugging\n",
    "\n",
    "1. **Profiling Tools**:\n",
    "   - Use profiling tools (e.g., `gprof`, `nvprof` for GPU jobs) to analyze the performance of your code. Profiling helps identify time-consuming functions and potential areas for optimization.\n",
    "\n",
    "2. **Debugging**:\n",
    "   - Use debugging tools to identify and fix issues in parallel code, ensuring that all processes and threads run as expected.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses the psutil library to monitor the memory usage of a Python script. It prints the memory usage at different stages of the computation, helping you identify parts of your code that consume a lot of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring Job Performance, Profiling, and Debugging: Interactive Coding Examples\n",
    "\n",
    "## 1. Monitor Job Performance\n",
    "\n",
    "### Example 1: Using Python to Monitor Memory Usage\n",
    "\n",
    "'''You can use Python to periodically monitor the memory usage \n",
    "of your script to identify potential memory leaks or inefficient \n",
    "memory usage.\n",
    "\n",
    "python'''\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "# Function to monitor memory usage\n",
    "def monitor_memory():\n",
    "    process = psutil.Process()\n",
    "    mem_info = process.memory_info()\n",
    "    print(f\"Memory Usage: {mem_info.rss / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "# Example function that uses memory\n",
    "def compute_large_array():\n",
    "    monitor_memory()  # Initial memory usage\n",
    "    large_array = [x ** 2 for x in range(10**6)]\n",
    "    monitor_memory()  # Memory usage after creating the array\n",
    "    del large_array\n",
    "    monitor_memory()  # Memory usage after deleting the array\n",
    "\n",
    "# Run the function and monitor memory usage\n",
    "compute_large_array()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using qstat to Monitor HPC Jobs\n",
    "\n",
    "If you are running jobs on an HPC system, you can use qstat (or similar job monitoring tools) to check the status of your jobs, including resource usage like CPU and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The qstat command provides a snapshot of your job's current status \n",
    "on the HPC cluster. It helps you monitor CPU usage, \n",
    "memory consumption, and job progress.'''\n",
    "\n",
    "# Command to check the status of your jobs\n",
    "qstat -u your_username\n",
    "\n",
    "# Command to get detailed information about a specific job\n",
    "qstat -f job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting Resource Requests in a Job Script\n",
    "\n",
    "If your job consistently underutilizes resources, you might need to adjust your resource requests to avoid wasting computational power.\n",
    "\n",
    "After analyzing the performance of your previous jobs using qstat, you might find that the job underutilizes CPU or memory. Adjust the --ntasks, --cpus-per-task, and --mem parameters in your SLURM job script based on the feedback to optimize resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# Example SLURM job script\n",
    "\n",
    "#SBATCH --job-name=example_job\n",
    "#SBATCH --ntasks=1                 # Number of tasks (should match CPU usage)\n",
    "#SBATCH --cpus-per-task=4          # Number of CPU cores per task\n",
    "#SBATCH --mem=8G                   # Memory per node\n",
    "#SBATCH --time=02:00:00            # Time limit\n",
    "\n",
    "module load python/3.8\n",
    "srun python my_script.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling with cProfile\n",
    "\n",
    "Python's cProfile module allows you to profile your code, identifying time-consuming functions and optimizing them for better performance.\n",
    "\n",
    "The example below uses cProfile to profile the example_function. The profiler will output the time spent in each function, allowing you to identify and optimize performance bottlenecks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "def example_function():\n",
    "    total = 0\n",
    "    for i in range(1, 1000000):\n",
    "        total += i ** 2\n",
    "    return total\n",
    "\n",
    "# Profile the example function\n",
    "cProfile.run('example_function()')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using nvprof for GPU Profiling\n",
    "\n",
    "If you are running code on a GPU, you can use NVIDIA's nvprof tool to profile your GPU code and identify performance bottlenecks.\n",
    "\n",
    "nvprof provides detailed insights into GPU utilization, memory transfers, and kernel execution times. This information helps you optimize your code for better GPU performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to profile a GPU-enabled script\n",
    "nvprof python my_gpu_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging with Python's pdb\n",
    "\n",
    "The pdb module is Python's built-in debugger, allowing you to step through your code, inspect variables, and fix issues.\n",
    "\n",
    "The example below sets a breakpoint with pdb.set_trace() before a line that will raise an error. Running this script will enter the pdb interactive debugging mode, where you can inspect variables, step through code, and understand the source of the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "def faulty_function():\n",
    "    x = 10\n",
    "    y = 0\n",
    "    pdb.set_trace()  # Set a breakpoint here\n",
    "    z = x / y  # This will raise a ZeroDivisionError\n",
    "    return z\n",
    "\n",
    "faulty_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Frequently Asked Questions**\n",
    "\n",
    "1. **Why is a tuple used when we have list?** \n",
    "\n",
    "**Answer:** Tuples are immutable while lists are mutable. We'd use a tuple when we do not want the values to be changed.  \n",
    "\n",
    "\n",
    "2. **Why do we prefer to write I/O in one go?**\n",
    "\n",
    "**Answer:** Writing I/O operations in one go reduces the overhead of opening, reading, and writing multiple times. This cuts down on the number of system calls, which can be slow, and it helps prevent issues like only part of the data required being processed. \n",
    "\n",
    "\n",
    "3. **What is in-memory computation, and why is it done?**  \n",
    "\n",
    "**Answer:** In-memory computation refers to storing data in a computing system's main memory (RAM) rather than reading from or writing to slower disk storage. It improves the performance of applications by avoiding the need to wait for data to be fetched from the disk.\n",
    "\n",
    "\n",
    "4. **What is a multi-threaded application?** \n",
    "\n",
    "**Answer:**  A multi-threaded application uses multiple threads of execution within a single process. These threads can run concurrently, letting the program handle several tasks simultaneously. This also improves efficiency and responsiveness.\n",
    "\n",
    "\n",
    "5. **What is thread affinity setting and why is it used?** \n",
    "\n",
    "**Answer:** Thread affinity refers to assigning a specific thread to a particular CPU core (or set of cores). It helps by keeping the thread on the same core, which can improve performance.\n",
    "\n",
    "\n",
    "6. **What is the difference between distributed memory and shared memory?**\n",
    "\n",
    "**Answer:** \n",
    "1. Distributed Memory: Each processor or computer node has its own private memory, and they communicate with each other by sending messages (for example, using MPI).\n",
    "\n",
    "2. Shared Memory: All processors share a common memory space, allowing them to exchange data directly (for example, using OpenMP).\n",
    "\n",
    "\n",
    "7. **What are I/O bottlenecks?**\n",
    "\n",
    "**Answer:** I/O bottlenecks happen when the speed at which data moves between storage devices (like hard drives or networks) and the computer is too slow compared to the processing speed. For example: If you send a 150 page document to the printer, your computer can process and send the data quickly, but the printer can only print a few pages per minute. Since the printer is slower than the computer, the printing process becomes a bottleneck leading to delays.\n",
    "\n",
    "\n",
    "8. **How does buffered I/O reduce memory usage and improve speed?**\n",
    "\n",
    "**Answer:** Buffered I/O improves performance by using a temporary storage area called a buffer. It can be slow and inefficient to process small pieces of data one by one. So, the system collects a larger amount of data in the buffer before reading or writing it all at once. This minimizes the constant switching between storage and processing and reduces the number of I/O operations, speeds up data transfer, and optimizes memory usage. \n",
    "\n",
    "\n",
    "9. **How do efficient file formats (example HDF5, NetCDF) support parallel I/O?**\n",
    "\n",
    "**Answer:** File formats like HDF5 and NetCDF are made so that many processes can access and work with the same file at the same time. This lets different parts of the file be read or written simultaneously which makes it much faster to handle large datasets.\n",
    "\n",
    "\n",
    "10. **What is profiling and how does it help in identifying inefficient resource usage?**\n",
    "\n",
    "**Answer:** Profiling is the process of analyzing a program’s performance by monitoring how it uses resources like CPU, memory, and disk I/O. It helps identify bottlenecks, inefficient code, or operations that slow down execution. This can help developers optimize specific parts of the program to address the problems identified. \n",
    "\n",
    "\n",
    "11. **what is GPU and GPU profiling?** \n",
    "\n",
    "**Answer:** A GPU is a specialized processor designed to handle complex calculations required for tasks like rendering images and performing parallel computations. It is a hardware component with thousands of small cores for complex computations. It also has high-bandwidth memory. GPU profiling is the process of analyzing how efficiently a program utilizes the GPU.\n",
    "\n",
    "\n",
    "12. **How does combining MPI (Message Passing Interface) with OpenMP (Open Multi-Processing) enhance parallelism in applications?**\n",
    "\n",
    "**Answer:** By combining MPI and OpenMP, applications can take advantage of two layers of parallelism. MPI enables multiple nodes to work on different parts of a problem at the same time. OpenMP, on the other hand, allows multiple cores within a single computer(or node) to run tasks concurrently. When combined together, they make it possible to split complex tasks efficiently across many processors. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
